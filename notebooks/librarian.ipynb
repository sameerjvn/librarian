{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sameer/repos/librarian/librarian-env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\")\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "{'source': '../data/pdf/sweden-visa-extension-2024.pdf'}\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vector Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = text_splitter.split_documents(docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 18/18 [00:50<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"llama3\", show_progress=True),\n",
    "    collection_name=\"local_rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"llama3\"\n",
    "llm = ChatOllama(model=local_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\"\n",
    ")\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    llm=llm,\n",
    "    prompt=query_prompt,\n",
    ")\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, this document appears to be related to instructions and checklists for attestation of studies in Sweden, specifically for students who need to extend their residence permit for studies. The documents seem to focus on providing guidelines for universities and colleges in Sweden to attest to a student's progress in their studies, with the aim of supporting the student's application for a residence permit extension.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is this document about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, there is no direct information on how a student applies for an extension. However, it can be inferred that the student would need to attach relevant documents, such as their transcript of records from Ladok including a presentation of course modules (completed and partially completed), when applying for a residence permit. Additionally, the Swedish Migration Agency may grant residence permits for studies outside the regular programme length if the reason for delay is known but not confirmed by the higher education institution.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How should a student apply for an extension?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "librarian-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
